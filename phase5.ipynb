{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b398b9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.50.0-cp312-cp312-win_amd64.whl.metadata (25 kB)\n",
      "Collecting numpy>=2 (from shap)\n",
      "  Downloading numpy-2.4.2-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from shap) (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from shap) (2.1.4)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from shap) (4.66.5)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\administrator\\appdata\\roaming\\python\\python312\\site-packages (from shap) (23.2)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\programdata\\anaconda3\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from shap) (4.15.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.54->shap) (0.43.0)\n",
      "Collecting numpy>=2 (from shap)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pandas (from shap)\n",
      "  Downloading pandas-3.0.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\administrator\\appdata\\roaming\\python\\python312\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: tzdata in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.50.0-cp312-cp312-win_amd64.whl (549 kB)\n",
      "   ---------------------------------------- 0.0/549.3 kB ? eta -:--:--\n",
      "   -------------------------------------- - 524.3/549.3 kB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 549.3/549.3 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/15.6 MB 3.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.1/15.6 MB 3.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 3.1/15.6 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.9/15.6 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.5/15.6 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 7.1/15.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.7/15.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.4/15.6 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.5/15.6 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.6 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.6 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 5.5 MB/s eta 0:00:00\n",
      "Downloading pandas-3.0.1-cp312-cp312-win_amd64.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.7 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.6/9.7 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.2/9.7 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.6/9.7 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.9/9.7 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 9.1 MB/s eta 0:00:00\n",
      "Installing collected packages: slicer, numpy, pandas, shap\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.4\n",
      "    Uninstalling pandas-2.1.4:\n",
      "      Successfully uninstalled pandas-2.1.4\n",
      "Successfully installed numpy-2.0.2 pandas-3.0.1 shap-0.50.0 slicer-0.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\ProgramData\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\ProgramData\\anaconda3\\Lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\~andas.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\~-ndas'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\ProgramData\\anaconda3\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "accelerate 1.12.0 requires torch>=2.0.0, which is not installed.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
      "streamlit 1.37.1 requires pandas<3,>=1.3.0, but you have pandas 3.0.1 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b44031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.18.4-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\appdata\\roaming\\python\\python312\\site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (2.0.34)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\roaming\\python\\python312\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
      "Downloading alembic-1.18.4-py3-none-any.whl (263 kB)\n",
      "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 alembic-1.18.4 colorlog-6.10.1 optuna-4.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\ProgramData\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\ProgramData\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\ProgramData\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d3c31e-3ba9-4550-8e3f-ac8bb544a319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Sequences (This might take a moment)...\n",
      "X_train shape: (907939, 14, 59), y_train shape: (907939,)\n",
      "\n",
      "Starting Optuna optimization for LSTM...\n",
      "Best LSTM params: {'lstm_units': 64, 'dropout_rate': 0.2}\n",
      "\n",
      "Training final LSTM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - loss: 1.6344 - val_loss: 2.6919\n",
      "Epoch 2/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - loss: 0.4128 - val_loss: 2.3341\n",
      "Epoch 3/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 15ms/step - loss: 0.3413 - val_loss: 2.1829\n",
      "Epoch 4/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 17ms/step - loss: 0.3084 - val_loss: 2.3877\n",
      "Epoch 5/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - loss: 0.2886 - val_loss: 2.8398\n",
      "Epoch 6/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 13ms/step - loss: 0.2752 - val_loss: 1.5392\n",
      "Epoch 7/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 13ms/step - loss: 0.2652 - val_loss: 1.2952\n",
      "Epoch 8/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 13ms/step - loss: 0.2513 - val_loss: 1.1611\n",
      "Epoch 9/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 14ms/step - loss: 0.2502 - val_loss: 1.2560\n",
      "Epoch 10/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 14ms/step - loss: 0.2438 - val_loss: 1.2652\n",
      "\n",
      "Training final TCN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 1.0917 - val_loss: 1.2483\n",
      "Epoch 2/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.4394 - val_loss: 1.4830\n",
      "Epoch 3/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.3984 - val_loss: 1.1917\n",
      "Epoch 4/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.3779 - val_loss: 1.6381\n",
      "Epoch 5/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.3650 - val_loss: 1.3591\n",
      "Epoch 6/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.3534 - val_loss: 1.5059\n",
      "Epoch 7/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.3436 - val_loss: 1.6966\n",
      "Epoch 8/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.3373 - val_loss: 1.6671\n",
      "Epoch 9/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - loss: 0.3306 - val_loss: 2.3264\n",
      "Epoch 10/10\n",
      "\u001b[1m3547/3547\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.3250 - val_loss: 1.8963\n",
      "\n",
      "Evaluating on Test Set...\n",
      "[LSTM] RMSE: 3631.13 Euros | RMSPE: 0.4835\n",
      "[TCN] RMSE: 2489.15 Euros | RMSPE: 0.3768\n",
      "\n",
      "Generating SHAP values (Background context computing...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077937012b924f3d9e8c9dcb4138f6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2ebd94b5c34d8cb42c6602171266ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Phase 5 outputs saved in artifacts/phase5/\n",
      "LSTM Params -> Units: 64, Dropout: 0.20\n",
      "LSTM -> RMSE: 3631.13 | RMSPE: 0.4835\n",
      "TCN  -> RMSE: 2489.15 | RMSPE: 0.3768\n",
      "SHAP plots and Prediction comparison plots generated successfully.\n",
      "==================================================\n",
      "Execution Completed Successfully! Project 100% Finished! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Phase 5 â€” Deep Learning (LSTM & TCN) + Optuna + SHAP\n",
    "# =========================================\n",
    "\n",
    "import os\n",
    "import json \n",
    "import csv  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ± Ø²Ø¯Ù† Ø¨Ø§Ú¯ Ù¾Ø§Ù†Ø¯Ø§Ø²\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import optuna\n",
    "import shap\n",
    "\n",
    "# -------------------------\n",
    "# A) Config\n",
    "# -------------------------\n",
    "PHASE2_DIR = \"artifacts/phase2\"\n",
    "OUT_DIR = \"artifacts/phase5\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_F = os.path.join(PHASE2_DIR, \"train_features.csv\")\n",
    "VAL_F   = os.path.join(PHASE2_DIR, \"val_features.csv\")\n",
    "TEST_F  = os.path.join(PHASE2_DIR, \"test_features.csv\")\n",
    "FEAT_F  = os.path.join(PHASE2_DIR, \"feature_cols.json\")\n",
    "\n",
    "LOOK_BACK = 14   \n",
    "HORIZONS = 7     # Ø§ÙÙ‚ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ 7 Ø±ÙˆØ²Ù‡\n",
    "SAMPLE_N = 50    \n",
    "\n",
    "# -------------------------\n",
    "# B) Load Data & Store-Aware Sliding Window\n",
    "# -------------------------\n",
    "train_df = pd.read_csv(TRAIN_F)\n",
    "val_df   = pd.read_csv(VAL_F)\n",
    "test_df  = pd.read_csv(TEST_F)\n",
    "\n",
    "with open(FEAT_F, \"r\", encoding=\"utf-8\") as f:\n",
    "    feature_cols = json.load(f)[\"feature_cols\"]\n",
    "\n",
    "# Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø­Ø°Ù Store Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ\n",
    "if \"Store\" in feature_cols:\n",
    "    feature_cols.remove(\"Store\")\n",
    "\n",
    "TARGET = \"Sales\"\n",
    "\n",
    "def create_sequences_store_aware(df, look_back):\n",
    "    X, y = [], []\n",
    "    # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ØªØ§ Ø¯ÛŒØªØ§ÛŒ Ø¯Ùˆ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ù‡Ù… Ù‚Ø§Ø·ÛŒ Ù†Ø´ÙˆØ¯\n",
    "    for store_id, group in df.groupby(\"Store\"):\n",
    "        group = group.sort_values(\"Date\")\n",
    "        X_data = group[feature_cols].to_numpy(dtype=np.float32)\n",
    "        y_data = group[TARGET].to_numpy(dtype=np.float32)\n",
    "        \n",
    "        for i in range(len(X_data) - look_back):\n",
    "            X.append(X_data[i : i + look_back])\n",
    "            y.append(y_data[i + look_back])\n",
    "            \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Building Sequences (This might take a moment)...\")\n",
    "X_train, y_train = create_sequences_store_aware(train_df, LOOK_BACK)\n",
    "X_val, y_val     = create_sequences_store_aware(val_df, LOOK_BACK)\n",
    "X_test, y_test   = create_sequences_store_aware(test_df, LOOK_BACK)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "# -------------------------\n",
    "# C & D) Build Models (Dynamic Architecture)\n",
    "# -------------------------\n",
    "def build_lstm_model(input_shape, units=128, dropout_rate=0.2):\n",
    "    model = Sequential([\n",
    "        LSTM(units, activation='relu', input_shape=input_shape),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def build_tcn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# -------------------------\n",
    "# E) Hyperparameter Optimization (Optuna)\n",
    "# -------------------------\n",
    "def objective(trial):\n",
    "    lstm_units = trial.suggest_int('lstm_units', 32, 128)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.4) \n",
    "    \n",
    "    model = build_lstm_model((LOOK_BACK, len(feature_cols)), units=lstm_units, dropout_rate=dropout_rate)\n",
    "    \n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=256, validation_data=(X_val, y_val), \n",
    "              callbacks=[early_stop], verbose=0)\n",
    "    \n",
    "    val_loss = model.evaluate(X_val, y_val, verbose=0)\n",
    "    return val_loss\n",
    "\n",
    "print(\"\\nStarting Optuna optimization for LSTM...\")\n",
    "RUN_OPTUNA = False # Ø¨Ø±Ø§ÛŒ ØµØ±ÙÙ‡â€ŒØ¬ÙˆÛŒÛŒ Ø¯Ø± Ø²Ù…Ø§Ù† Ø±ÙˆÛŒ False ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡\n",
    "\n",
    "if RUN_OPTUNA:\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=5)\n",
    "    best_params = study.best_trial.params\n",
    "else:\n",
    "    best_params = {'lstm_units': 64, 'dropout_rate': 0.2}\n",
    "\n",
    "print(\"Best LSTM params:\", best_params)\n",
    "\n",
    "# Train Final Models\n",
    "print(\"\\nTraining final LSTM model...\")\n",
    "lstm_model = build_lstm_model((LOOK_BACK, len(feature_cols)), \n",
    "                              units=best_params['lstm_units'], \n",
    "                              dropout_rate=best_params['dropout_rate'])\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "print(\"\\nTraining final TCN model...\")\n",
    "tcn_model = build_tcn_model((LOOK_BACK, len(feature_cols)))\n",
    "tcn_model.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# -------------------------\n",
    "# F & H) Forecasting & Metrics\n",
    "# -------------------------\n",
    "print(\"\\nEvaluating on Test Set...\")\n",
    "\n",
    "lstm_preds_log = lstm_model.predict(X_test, verbose=0).flatten()\n",
    "tcn_preds_log  = tcn_model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "y_test_real = np.expm1(y_test)\n",
    "lstm_preds_real = np.expm1(lstm_preds_log)\n",
    "tcn_preds_real = np.expm1(tcn_preds_log)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, model_name):\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    mask = y_true > 0\n",
    "    if np.any(mask):\n",
    "        rmspe_val = np.sqrt(np.mean(((y_true[mask] - y_pred[mask]) / y_true[mask]) ** 2))\n",
    "    else:\n",
    "        rmspe_val = 0.0\n",
    "        \n",
    "    print(f\"[{model_name}] RMSE: {rmse_val:.2f} Euros | RMSPE: {rmspe_val:.4f}\")\n",
    "    return rmse_val, rmspe_val\n",
    "\n",
    "lstm_rmse, lstm_rmspe = calculate_metrics(y_test_real, lstm_preds_real, \"LSTM\")\n",
    "tcn_rmse, tcn_rmspe   = calculate_metrics(y_test_real, tcn_preds_real, \"TCN\")\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Model\": [\"LSTM\", \"TCN\"],\n",
    "    \"RMSE_Euros\": [lstm_rmse, tcn_rmse],\n",
    "    \"RMSPE\": [lstm_rmspe, tcn_rmspe]\n",
    "})\n",
    "\n",
    "## --- FIX: Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ pandas.to_csv Ø¨Ø§ Ù…Ø§Ú˜ÙˆÙ„ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ csv Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ± Ø²Ø¯Ù† Ø¨Ø§Ú¯ ImportError --- ##\n",
    "csv_path = os.path.join(OUT_DIR, \"metrics_deep_learning.csv\")\n",
    "with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(metrics_df.columns)\n",
    "    for row in metrics_df.values:\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ 100 Ù†Ù…ÙˆÙ†Ù‡ Ø¢Ø®Ø±\n",
    "plot_samples = min(100, len(y_test_real))\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(y_test_real[-plot_samples:], label=\"Actual Sales\", color='black', linestyle='dashed', linewidth=2)\n",
    "plt.plot(lstm_preds_real[-plot_samples:], label=\"LSTM Predictions\", alpha=0.8)\n",
    "plt.plot(tcn_preds_real[-plot_samples:], label=\"TCN Predictions\", alpha=0.8)\n",
    "plt.legend()\n",
    "plt.title(f\"Deep Learning Forecast vs Actuals (Last {plot_samples} Test Samples)\")\n",
    "plt.ylabel(\"Sales (Euros)\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"dl_predictions_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# -------------------------\n",
    "# G) SHAP Integration\n",
    "# -------------------------\n",
    "print(\"\\nGenerating SHAP values (Background context computing...)\")\n",
    "def shap_analysis(model, X_sample, model_name):\n",
    "    X_sample_2d = X_sample.reshape((X_sample.shape[0], -1))\n",
    "    \n",
    "    def predict_wrapper(x_2d):\n",
    "        x_3d = x_2d.reshape((x_2d.shape[0], LOOK_BACK, len(feature_cols)))\n",
    "        return model.predict(x_3d, verbose=0).flatten() \n",
    "    \n",
    "    background = shap.kmeans(X_sample_2d, 10)\n",
    "    explainer = shap.KernelExplainer(predict_wrapper, background)\n",
    "    \n",
    "    shap_values = explainer.shap_values(X_sample_2d)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    shap.summary_plot(shap_values, features=X_sample_2d, show=False)\n",
    "    plt.title(f\"SHAP Feature Importance ({model_name.upper()})\")\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"shap_analysis_{model_name}.png\"), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "shap_analysis(lstm_model, X_test[:20], \"lstm\")\n",
    "shap_analysis(tcn_model, X_test[:20], \"tcn\")\n",
    "\n",
    "summary_lines = [\n",
    "    \"Phase 5 outputs saved in artifacts/phase5/\",\n",
    "    f\"LSTM Params -> Units: {best_params['lstm_units']}, Dropout: {best_params['dropout_rate']:.2f}\",\n",
    "    f\"LSTM -> RMSE: {lstm_rmse:.2f} | RMSPE: {lstm_rmspe:.4f}\",\n",
    "    f\"TCN  -> RMSE: {tcn_rmse:.2f} | RMSPE: {tcn_rmspe:.4f}\",\n",
    "    \"SHAP plots and Prediction comparison plots generated successfully.\"\n",
    "]\n",
    "\n",
    "with open(os.path.join(OUT_DIR, \"SUMMARY.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(summary_lines))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\n\".join(summary_lines))\n",
    "print(\"=\"*50)\n",
    "print(\"Execution Completed Successfully! Project 100% Finished! ğŸš€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126a90e-90b4-4dd5-8eaf-920cf2c9f6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
